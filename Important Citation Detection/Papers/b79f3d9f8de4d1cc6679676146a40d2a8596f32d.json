{
  "authors": [
    {
      "authorId": "12374067", 
      "name": "Siming Li", 
      "url": "https://www.semanticscholar.org/author/12374067"
    }, 
    {
      "authorId": "6950922", 
      "name": "Girish Kulkarni", 
      "url": "https://www.semanticscholar.org/author/6950922"
    }, 
    {
      "authorId": "1685538", 
      "name": "Tamara L. Berg", 
      "url": "https://www.semanticscholar.org/author/1685538"
    }, 
    {
      "authorId": "1743555", 
      "name": "Alexander C. Berg", 
      "url": "https://www.semanticscholar.org/author/1743555"
    }, 
    {
      "authorId": "1699545", 
      "name": "Yejin Choi", 
      "url": "https://www.semanticscholar.org/author/1699545"
    }
  ], 
  "citationVelocity": 33, 
  "citations": [
    {
      "isInfluential": false, 
      "paperId": "8120a64a73b89294990b3c1e4567b503869b8979", 
      "title": "Stories in the Eye: Contextual Visual Interactions for Efficient Video to Language Translation", 
      "url": "https://www.semanticscholar.org/paper/8120a64a73b89294990b3c1e4567b503869b8979"
    }, 
    {
      "isInfluential": false, 
      "paperId": "ef3f78ebf6a36a1d49b8a8a6c8bddf9f906285b8", 
      "title": "Im2Text and Text2Im: Associating Images and Texts for Cross-Modal Retrieval", 
      "url": "https://www.semanticscholar.org/paper/ef3f78ebf6a36a1d49b8a8a6c8bddf9f906285b8"
    }, 
    {
      "isInfluential": false, 
      "paperId": "e65efc631b86dc9c18f459c935199cef86ba7ba0", 
      "title": "Generating natural language tags for video information management", 
      "url": "https://www.semanticscholar.org/paper/e65efc631b86dc9c18f459c935199cef86ba7ba0"
    }, 
    {
      "isInfluential": false, 
      "paperId": "d8d2cc5bfac5a5ec19897c0e77c2f39b829eb0d3", 
      "title": "Towards Diverse and Natural Image Descriptions via a Conditional GAN", 
      "url": "https://www.semanticscholar.org/paper/d8d2cc5bfac5a5ec19897c0e77c2f39b829eb0d3"
    }, 
    {
      "isInfluential": false, 
      "paperId": "5c50caaa3983b4377f8bbf572e1c13fb49b3d601", 
      "title": "Leveraging High Level Visual Information for Matching Images and Captions", 
      "url": "https://www.semanticscholar.org/paper/5c50caaa3983b4377f8bbf572e1c13fb49b3d601"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0058998b4274ae99e50b8877c075638d56dd4c3c", 
      "title": "Image Captioning and Visual Question Answering Based on Attributes and External Knowledge.", 
      "url": "https://www.semanticscholar.org/paper/0058998b4274ae99e50b8877c075638d56dd4c3c"
    }, 
    {
      "isInfluential": false, 
      "paperId": "b5793958cd1654b4817ebb57f5484dfd8861f916", 
      "title": "Recurrent Image Captioner: Describing Images with Spatial-Invariant Transformation and Attention Filtering", 
      "url": "https://www.semanticscholar.org/paper/b5793958cd1654b4817ebb57f5484dfd8861f916"
    }, 
    {
      "isInfluential": false, 
      "paperId": "4cedfe1544defca798f700ab50ef390edbfe4e63", 
      "title": "Selecting Relevant Web Trained Concepts for Automated Event Retrieval", 
      "url": "https://www.semanticscholar.org/paper/4cedfe1544defca798f700ab50ef390edbfe4e63"
    }, 
    {
      "isInfluential": true, 
      "paperId": "9814df8bd00ba999c4d1e305a7e9bca579dc7c75", 
      "title": "Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics", 
      "url": "https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75"
    }, 
    {
      "isInfluential": false, 
      "paperId": "34c1ae7fdd00b4e46959443728e1a586bd78c74a", 
      "title": "On the use of commonsense ontology for multimedia event recounting", 
      "url": "https://www.semanticscholar.org/paper/34c1ae7fdd00b4e46959443728e1a586bd78c74a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "09a99ca583b0eff0a34de32b4eed23d6d8ff14c2", 
      "title": "Domain-Independent Captioning of Domain-Specific Images", 
      "url": "https://www.semanticscholar.org/paper/09a99ca583b0eff0a34de32b4eed23d6d8ff14c2"
    }, 
    {
      "isInfluential": false, 
      "paperId": "627107c02c2df1366965f11678dd3c4fb14ac9b3", 
      "title": "Connecting Images and Natural Language a Dissertation Submitted to the Department of Computer Science and the Committee on Graduate Studies of Stanford University in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy", 
      "url": "https://www.semanticscholar.org/paper/627107c02c2df1366965f11678dd3c4fb14ac9b3"
    }, 
    {
      "isInfluential": false, 
      "paperId": "865d6d32fd0789ff24f7bb4d5caac35ffdcc24a0", 
      "title": "A general description generator for human activity images based on deep understanding framework", 
      "url": "https://www.semanticscholar.org/paper/865d6d32fd0789ff24f7bb4d5caac35ffdcc24a0"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0ba87571341beaf6a5c9a30e049be7b1fc9a4c60", 
      "title": "Choosing Linguistics over Vision to Describe Images", 
      "url": "https://www.semanticscholar.org/paper/0ba87571341beaf6a5c9a30e049be7b1fc9a4c60"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0d0a348510cb2fbefbb3225ee18fafc1479eaeef", 
      "title": "Multi-Language Image Description with Neural Sequence Models", 
      "url": "https://www.semanticscholar.org/paper/0d0a348510cb2fbefbb3225ee18fafc1479eaeef"
    }, 
    {
      "isInfluential": false, 
      "paperId": "3abc833f4d689f37cc8a28f47fb42e32deaa4b17", 
      "title": "Large Scale Retrieval and Generation of Image Descriptions", 
      "url": "https://www.semanticscholar.org/paper/3abc833f4d689f37cc8a28f47fb42e32deaa4b17"
    }, 
    {
      "isInfluential": false, 
      "paperId": "10c54d469dfa6b1562d8a3f06d7adf8b79581ed7", 
      "title": "Automated Measures of Specific Vocabulary Knowledge from Constructed Responses ('Use These Words to Write a Sentence Based on this Picture')", 
      "url": "https://www.semanticscholar.org/paper/10c54d469dfa6b1562d8a3f06d7adf8b79581ed7"
    }, 
    {
      "isInfluential": false, 
      "paperId": "f9eedcb217f288f91e5bc3b62a0820244f920eee", 
      "title": "Towards Succinct and Relevant Image Descriptions", 
      "url": "https://www.semanticscholar.org/paper/f9eedcb217f288f91e5bc3b62a0820244f920eee"
    }, 
    {
      "isInfluential": false, 
      "paperId": "355de7460120ddc1150d9ce3756f9848983f7ff4", 
      "title": "Midge: Generating Image Descriptions From Computer Vision Detections", 
      "url": "https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4"
    }, 
    {
      "isInfluential": false, 
      "paperId": "20c1056dd7fc0d2a1f2c9b860dfbefbd530dc636", 
      "title": "Image specificity", 
      "url": "https://www.semanticscholar.org/paper/20c1056dd7fc0d2a1f2c9b860dfbefbd530dc636"
    }, 
    {
      "isInfluential": true, 
      "paperId": "0d8e450061855af48c07d422f9f96b79f68d8c77", 
      "title": "Comparing Automatic Evaluation Measures for Image Description", 
      "url": "https://www.semanticscholar.org/paper/0d8e450061855af48c07d422f9f96b79f68d8c77"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1dab64439ffb72da80175ba98a47b6f1e0ddd21b", 
      "title": "The Use of Object Labels and Spatial Prepositions as Keywords in a Web-Retrieval-Based Image Caption Generation System", 
      "url": "https://www.semanticscholar.org/paper/1dab64439ffb72da80175ba98a47b6f1e0ddd21b"
    }, 
    {
      "isInfluential": false, 
      "paperId": "cac571e2e2d37b712055196e87d57a8da742e7cb", 
      "title": "Modelling Salient Object-Object Interactions to Generate Textual Descriptions for Natural Images", 
      "url": "https://www.semanticscholar.org/paper/cac571e2e2d37b712055196e87d57a8da742e7cb"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0f05eb2c216097ae75542f951413a4e0a5513db5", 
      "title": "Predictable Dual-View Hashing", 
      "url": "https://www.semanticscholar.org/paper/0f05eb2c216097ae75542f951413a4e0a5513db5"
    }, 
    {
      "isInfluential": false, 
      "paperId": "a94ad26c47691e70e7a37e5f95775d4d754c2614", 
      "title": "What Value Do Explicit High Level Concepts Have in Vision to Language Problems?", 
      "url": "https://www.semanticscholar.org/paper/a94ad26c47691e70e7a37e5f95775d4d754c2614"
    }, 
    {
      "isInfluential": false, 
      "paperId": "01efec88d36070dc3bc49f341a77476f74d373bc", 
      "title": "Generation and Comprehension of Unambiguous Object Descriptions", 
      "url": "https://www.semanticscholar.org/paper/01efec88d36070dc3bc49f341a77476f74d373bc"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1aef6f7d2e3565f29125a4871cd60c4d86c48361", 
      "title": "Subhashini VenugopalanProposal", 
      "url": "https://www.semanticscholar.org/paper/1aef6f7d2e3565f29125a4871cd60c4d86c48361"
    }, 
    {
      "isInfluential": false, 
      "paperId": "08e76cdd6a18f03c8ac11a05898c2b1ea7e283ed", 
      "title": "Deep Fragment Embeddings for Bidirectional Image Sentence Mapping", 
      "url": "https://www.semanticscholar.org/paper/08e76cdd6a18f03c8ac11a05898c2b1ea7e283ed"
    }, 
    {
      "isInfluential": false, 
      "paperId": "f2617da2d4a0466784809981babcdb7f697b5f24", 
      "title": "Fine-grained attention for image caption generation", 
      "url": "https://www.semanticscholar.org/paper/f2617da2d4a0466784809981babcdb7f697b5f24"
    }, 
    {
      "isInfluential": false, 
      "paperId": "16f983629e0b56688b06e2f6679dfc397e677c8a", 
      "title": "Integrating Language and Vision to Generate Natural Language Descriptions of Videos in the Wild", 
      "url": "https://www.semanticscholar.org/paper/16f983629e0b56688b06e2f6679dfc397e677c8a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "2e36ea91a3c8fbff92be2989325531b4002e2afc", 
      "title": "Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models", 
      "url": "https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc"
    }, 
    {
      "isInfluential": false, 
      "paperId": "04483e2c56695b19f6912b061769eb8c175a5a7a", 
      "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions", 
      "url": "https://www.semanticscholar.org/paper/04483e2c56695b19f6912b061769eb8c175a5a7a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "f126ec304cdad464f6248ac7f73a186ca26db526", 
      "title": "Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)", 
      "url": "https://www.semanticscholar.org/paper/f126ec304cdad464f6248ac7f73a186ca26db526"
    }, 
    {
      "isInfluential": false, 
      "paperId": "4764257e844f11e57ff72159bdcfb3dbfe17816a", 
      "title": "Prominent Object Detection and Recognition: A Saliency-based Pipeline", 
      "url": "https://www.semanticscholar.org/paper/4764257e844f11e57ff72159bdcfb3dbfe17816a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "108961c7366e36825ffed94ac9eab603e05b6bc6", 
      "title": "Deep Visual-Semantic Alignments for Generating Image Descriptions", 
      "url": "https://www.semanticscholar.org/paper/108961c7366e36825ffed94ac9eab603e05b6bc6"
    }, 
    {
      "isInfluential": false, 
      "paperId": "5e286a45a4780a142e1420728ab99cb92993ab50", 
      "title": "Data-driven image captioning with meta-class based retrieval", 
      "url": "https://www.semanticscholar.org/paper/5e286a45a4780a142e1420728ab99cb92993ab50"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1d672521ed4ee20e48ced7d5e531e7a45a6c72b7", 
      "title": "Generating Natural-Language Video Descriptions Using Text-Mined Knowledge", 
      "url": "https://www.semanticscholar.org/paper/1d672521ed4ee20e48ced7d5e531e7a45a6c72b7"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0e0900b88c33b671be5dd2ded9885b6526d6b429", 
      "title": "From captions to visual concepts and back", 
      "url": "https://www.semanticscholar.org/paper/0e0900b88c33b671be5dd2ded9885b6526d6b429"
    }, 
    {
      "isInfluential": false, 
      "paperId": "6e6923a8b39cd22d714ae9364d18bec8178e5632", 
      "title": "Generating Image Descriptions Using Semantic Similarities in the Output Space", 
      "url": "https://www.semanticscholar.org/paper/6e6923a8b39cd22d714ae9364d18bec8178e5632"
    }, 
    {
      "isInfluential": false, 
      "paperId": "a360526696a2698ad31dfca4c529e098d2dbdbd1", 
      "title": "Image Captioning with Semantic Attention", 
      "url": "https://www.semanticscholar.org/paper/a360526696a2698ad31dfca4c529e098d2dbdbd1"
    }, 
    {
      "isInfluential": false, 
      "paperId": "46a1172c784c3741e79781ef2353209b08dbea67", 
      "title": "YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition", 
      "url": "https://www.semanticscholar.org/paper/46a1172c784c3741e79781ef2353209b08dbea67"
    }, 
    {
      "isInfluential": false, 
      "paperId": "3f6a4556769e819242d669d073b895f1e45a706f", 
      "title": "Image Description using Visual Dependency Representations", 
      "url": "https://www.semanticscholar.org/paper/3f6a4556769e819242d669d073b895f1e45a706f"
    }, 
    {
      "isInfluential": false, 
      "paperId": "b4451d8e34e92abe8dceb425b3e41cb5fe948739", 
      "title": "Generating video description with Long-Short Term Memory", 
      "url": "https://www.semanticscholar.org/paper/b4451d8e34e92abe8dceb425b3e41cb5fe948739"
    }, 
    {
      "isInfluential": false, 
      "paperId": "3bfa75238e15e869b902ceb62b31ffddbe8ccb0d", 
      "title": "Describing Images using Inferred Visual Dependency Representations", 
      "url": "https://www.semanticscholar.org/paper/3bfa75238e15e869b902ceb62b31ffddbe8ccb0d"
    }, 
    {
      "isInfluential": true, 
      "paperId": "5060e2e7d94e002a5376f4edfd2e48ac01d6221f", 
      "title": "Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures", 
      "url": "https://www.semanticscholar.org/paper/5060e2e7d94e002a5376f4edfd2e48ac01d6221f"
    }, 
    {
      "isInfluential": false, 
      "paperId": "936c7406de1dfdd22493785fc5d1e5614c6c2882", 
      "title": "Detecting Visual Text", 
      "url": "https://www.semanticscholar.org/paper/936c7406de1dfdd22493785fc5d1e5614c6c2882"
    }, 
    {
      "isInfluential": false, 
      "paperId": "d13bb317e87f3f6da10da11059ebf4350b754814", 
      "title": "Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation", 
      "url": "https://www.semanticscholar.org/paper/d13bb317e87f3f6da10da11059ebf4350b754814"
    }, 
    {
      "isInfluential": false, 
      "paperId": "4fa6a688f350831503d158f8f618c58d1e06bc5d", 
      "title": "A Semi-supervised Framework for Image Captioning", 
      "url": "https://www.semanticscholar.org/paper/4fa6a688f350831503d158f8f618c58d1e06bc5d"
    }, 
    {
      "isInfluential": false, 
      "paperId": "223707c08ff145aec85ac74cd5d8416b50fe1dc6", 
      "title": "A corpus of science journalism for analyzing writing quality", 
      "url": "https://www.semanticscholar.org/paper/223707c08ff145aec85ac74cd5d8416b50fe1dc6"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0b808d6d3d652d13df90ceb00be56bf4684c5c9a", 
      "title": "A multimodal framework for unsupervised feature fusion", 
      "url": "https://www.semanticscholar.org/paper/0b808d6d3d652d13df90ceb00be56bf4684c5c9a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "26e425781e4090abfae65b5d68eac72282dd2e31", 
      "title": "Image Captioning with Deep Bidirectional LSTMs", 
      "url": "https://www.semanticscholar.org/paper/26e425781e4090abfae65b5d68eac72282dd2e31"
    }, 
    {
      "isInfluential": true, 
      "paperId": "b86a3953682331302eeae1d977b1306038d4df53", 
      "title": "Efficient image annotation for automatic sentence generation", 
      "url": "https://www.semanticscholar.org/paper/b86a3953682331302eeae1d977b1306038d4df53"
    }, 
    {
      "isInfluential": false, 
      "paperId": "214f552070a7eb5ef5efe0d6ffeaaa594a3c3535", 
      "title": "Learning Everything about Anything: Webly-Supervised Visual Concept Learning", 
      "url": "https://www.semanticscholar.org/paper/214f552070a7eb5ef5efe0d6ffeaaa594a3c3535"
    }, 
    {
      "isInfluential": false, 
      "paperId": "adc97e0c7b64d95b2244b96d8978dd02b088ddf7", 
      "title": "StyleNet: Generating Attractive Visual Captions with Styles", 
      "url": "https://www.semanticscholar.org/paper/adc97e0c7b64d95b2244b96d8978dd02b088ddf7"
    }, 
    {
      "isInfluential": true, 
      "paperId": "0f6d068ca799e99100fa5ff7503163fd1c9ae581", 
      "title": "Common Subspace for Model and Similarity: Phrase Learning for Caption Generation from Images", 
      "url": "https://www.semanticscholar.org/paper/0f6d068ca799e99100fa5ff7503163fd1c9ae581"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1b89cc4a54c375b7f57b90641c2b585894a29633", 
      "title": "Associating neural word embeddings with deep image representations using Fisher Vectors", 
      "url": "https://www.semanticscholar.org/paper/1b89cc4a54c375b7f57b90641c2b585894a29633"
    }, 
    {
      "isInfluential": false, 
      "paperId": "56ffece2817a0363f551210733a611830ba1155d", 
      "title": "Aligning where to see and what to tell: image caption with region-based attention and scene factorization", 
      "url": "https://www.semanticscholar.org/paper/56ffece2817a0363f551210733a611830ba1155d"
    }, 
    {
      "isInfluential": false, 
      "paperId": "61d409b92860480a9188d23ba59b822ddc6331f9", 
      "title": "Multimodal Video Description", 
      "url": "https://www.semanticscholar.org/paper/61d409b92860480a9188d23ba59b822ddc6331f9"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0f390c9474d09726ccfd6df7469ee54fe23da280", 
      "title": "Collective Generation of Natural Image Descriptions", 
      "url": "https://www.semanticscholar.org/paper/0f390c9474d09726ccfd6df7469ee54fe23da280"
    }, 
    {
      "isInfluential": true, 
      "paperId": "2e3c8c8a413a317295bd44d86d089ed70a0b0c29", 
      "title": "Introducing Concept And Syntax Transition Networks for Image Captioning", 
      "url": "https://www.semanticscholar.org/paper/2e3c8c8a413a317295bd44d86d089ed70a0b0c29"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1cc9231af7293ab4ff2edea273b786eca2ec9f55", 
      "title": "Generating Image Descriptions with Gold Standard Visual Inputs: Motivation, Evaluation and Baselines", 
      "url": "https://www.semanticscholar.org/paper/1cc9231af7293ab4ff2edea273b786eca2ec9f55"
    }, 
    {
      "isInfluential": false, 
      "paperId": "6e60536c847ac25dba4c1c071e0355e5537fe061", 
      "title": "Computer Vision and Natural Language Processing: Recent Approaches in Multimedia and Robotics", 
      "url": "https://www.semanticscholar.org/paper/6e60536c847ac25dba4c1c071e0355e5537fe061"
    }, 
    {
      "isInfluential": false, 
      "paperId": "561008cb23d7a38a00806353ba3389c1b95395af", 
      "title": "Movie Description", 
      "url": "https://www.semanticscholar.org/paper/561008cb23d7a38a00806353ba3389c1b95395af"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0041afaf2b17f1a33bd514db27b17ce34670fdb8", 
      "title": "Deep Reinforcement Learning-based Image Captioning with Embedding Reward", 
      "url": "https://www.semanticscholar.org/paper/0041afaf2b17f1a33bd514db27b17ce34670fdb8"
    }, 
    {
      "isInfluential": false, 
      "paperId": "aa09ade36424fd83f067f234baffde294800e705", 
      "title": "Is a Picture Worth Ten Thousand Words in a Review Dataset?", 
      "url": "https://www.semanticscholar.org/paper/aa09ade36424fd83f067f234baffde294800e705"
    }, 
    {
      "isInfluential": false, 
      "paperId": "3d275a4e4f44d452f21e0e0ff6145a5e18e6cf87", 
      "title": "CIDEr: Consensus-based image description evaluation", 
      "url": "https://www.semanticscholar.org/paper/3d275a4e4f44d452f21e0e0ff6145a5e18e6cf87"
    }, 
    {
      "isInfluential": false, 
      "paperId": "c491fc710a671dcb55266264627fe9e155f703f1", 
      "title": "LSTM-in-LSTM for generating long descriptions of images", 
      "url": "https://www.semanticscholar.org/paper/c491fc710a671dcb55266264627fe9e155f703f1"
    }, 
    {
      "isInfluential": false, 
      "paperId": "11da2d589485685f792a8ac79d4c2e589e5f77bd", 
      "title": "Show and tell: A neural image caption generator", 
      "url": "https://www.semanticscholar.org/paper/11da2d589485685f792a8ac79d4c2e589e5f77bd"
    }, 
    {
      "isInfluential": false, 
      "paperId": "00fe3d95d0fd5f1433d81405bee772c4fe9af9c6", 
      "title": "Image Captioning with an Intermediate Attributes Layer", 
      "url": "https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6"
    }, 
    {
      "isInfluential": false, 
      "paperId": "4898e0c5bb8d93443f2f168c31e3f1827c9129de", 
      "title": "Fisher Vectors Derived from Hybrid Gaussian-Laplacian Mixture Models for Image Annotation", 
      "url": "https://www.semanticscholar.org/paper/4898e0c5bb8d93443f2f168c31e3f1827c9129de"
    }, 
    {
      "isInfluential": false, 
      "paperId": "129d716338dd2eb7712b53a406b508e277aab469", 
      "title": "Image Caption Generation with Text-Conditional Semantic Attention", 
      "url": "https://www.semanticscholar.org/paper/129d716338dd2eb7712b53a406b508e277aab469"
    }, 
    {
      "isInfluential": false, 
      "paperId": "b9ed0bb4aae5d89c48ce2ce372f2891c228fe0f8", 
      "title": "Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections", 
      "url": "https://www.semanticscholar.org/paper/b9ed0bb4aae5d89c48ce2ce372f2891c228fe0f8"
    }, 
    {
      "isInfluential": false, 
      "paperId": "31c197a0e30f1aeb1414634968d1649e74cd8d0f", 
      "title": "Deep correlation for matching images and text", 
      "url": "https://www.semanticscholar.org/paper/31c197a0e30f1aeb1414634968d1649e74cd8d0f"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0e6ac426e8916e6c429f4243cbddd6c44aadeba7", 
      "title": "Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge", 
      "url": "https://www.semanticscholar.org/paper/0e6ac426e8916e6c429f4243cbddd6c44aadeba7"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0ef738100a7c79e0aa3c9b9dfd5975c504c7aa5d", 
      "title": "Using the Visual Denotations of Image Captions for Semantic Inference", 
      "url": "https://www.semanticscholar.org/paper/0ef738100a7c79e0aa3c9b9dfd5975c504c7aa5d"
    }, 
    {
      "isInfluential": false, 
      "paperId": "f528b8c80f5420cea76d96520ec81bd9f52caa41", 
      "title": "Midge: Generating Descriptions of Images", 
      "url": "https://www.semanticscholar.org/paper/f528b8c80f5420cea76d96520ec81bd9f52caa41"
    }, 
    {
      "isInfluential": false, 
      "paperId": "529341eb910ca5125b4aa6aa83bfc5fc8bf44fe3", 
      "title": "V&L Net 2014 The 3rd Annual Meeting Of The EPSRC Network On Vision & Language and The 1st Technical Meeting of the European Network on Integrating Vision and Language", 
      "url": "https://www.semanticscholar.org/paper/529341eb910ca5125b4aa6aa83bfc5fc8bf44fe3"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1a4bc1821e32acc3a2a8dbd9774b8d201e9f11b9", 
      "title": "Understanding and predicting importance in images", 
      "url": "https://www.semanticscholar.org/paper/1a4bc1821e32acc3a2a8dbd9774b8d201e9f11b9"
    }, 
    {
      "isInfluential": false, 
      "paperId": "2f598922f81e65c1f3ffbd8c2456d2e9dcd7124a", 
      "title": "Interleaved Text/Image Deep Mining on a Large-Scale Radiology Database for Automated Image Interpretation", 
      "url": "https://www.semanticscholar.org/paper/2f598922f81e65c1f3ffbd8c2456d2e9dcd7124a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "c012c439c44c57c41a7ba3ca55f83cd4cb3c232a", 
      "title": "Aligning Where to See and What to Tell: Image Captioning with Region-based Attention and Scene-specific Contexts.", 
      "url": "https://www.semanticscholar.org/paper/c012c439c44c57c41a7ba3ca55f83cd4cb3c232a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "f4d2bdccd4dddb6e2bbba412d740299a723c708a", 
      "title": "A Structured Repre S Entat Ion of Image S for Language Generat Ion and Image Retr I Eval", 
      "url": "https://www.semanticscholar.org/paper/f4d2bdccd4dddb6e2bbba412d740299a723c708a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "4be79ee47771c670aa63bcdaff870f9dd8575a0d", 
      "title": "phi-LSTM: A Phrase-based Hierarchical LSTM Model for Image Captioning", 
      "url": "https://www.semanticscholar.org/paper/4be79ee47771c670aa63bcdaff870f9dd8575a0d"
    }, 
    {
      "isInfluential": false, 
      "paperId": "53e9d718ec981850cfc6110385ac42ca2da2f612", 
      "title": "Learning CNN-LSTM Architectures for Image Caption Generation", 
      "url": "https://www.semanticscholar.org/paper/53e9d718ec981850cfc6110385ac42ca2da2f612"
    }, 
    {
      "isInfluential": false, 
      "paperId": "37cf2d90af742650274acc88f0cbfd94916cfd81", 
      "title": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language", 
      "url": "https://www.semanticscholar.org/paper/37cf2d90af742650274acc88f0cbfd94916cfd81"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1576fa1acde38dc59c27607cb5276cbb179cd050", 
      "title": "Re-evaluating Automatic Metrics for Image Captioning", 
      "url": "https://www.semanticscholar.org/paper/1576fa1acde38dc59c27607cb5276cbb179cd050"
    }, 
    {
      "isInfluential": false, 
      "paperId": "146f6f6ed688c905fb6e346ad02332efd5464616", 
      "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention", 
      "url": "https://www.semanticscholar.org/paper/146f6f6ed688c905fb6e346ad02332efd5464616"
    }, 
    {
      "isInfluential": false, 
      "paperId": "e9a891bd087f1bb6e0f77dde8a72b80b54655538", 
      "title": "Learning to Generate Descriptions of Visual Data Anchored in Spatial Relations", 
      "url": "https://www.semanticscholar.org/paper/e9a891bd087f1bb6e0f77dde8a72b80b54655538"
    }, 
    {
      "isInfluential": false, 
      "paperId": "de09cb5eeff5e7a752567c009f7621dfa6ebb2da", 
      "title": "Generating Affective Captions using Concept And Syntax Transition Networks", 
      "url": "https://www.semanticscholar.org/paper/de09cb5eeff5e7a752567c009f7621dfa6ebb2da"
    }, 
    {
      "isInfluential": false, 
      "paperId": "217328b21f224e0bc7d81e482611b2651949a279", 
      "title": "Multimodal Machine Learning: A Survey and Taxonomy", 
      "url": "https://www.semanticscholar.org/paper/217328b21f224e0bc7d81e482611b2651949a279"
    }, 
    {
      "isInfluential": false, 
      "paperId": "88c307c51594c6d802080a0780d0d654e2e2891f", 
      "title": "Visual Question Answering: A Survey of Methods and Datasets", 
      "url": "https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1c90ad1e264c29a8d180de47373257a5f1b5aa57", 
      "title": "Generalizing Image Captions for Image-Text Parallel Corpus", 
      "url": "https://www.semanticscholar.org/paper/1c90ad1e264c29a8d180de47373257a5f1b5aa57"
    }, 
    {
      "isInfluential": false, 
      "paperId": "d6d6edce271935feec96484d0e1f16dcc24973fd", 
      "title": "Exploiting Scene Context for Image Captioning", 
      "url": "https://www.semanticscholar.org/paper/d6d6edce271935feec96484d0e1f16dcc24973fd"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0a904577358b9bae70d06c528adbcb6aa55d55bd", 
      "title": "Skeleton Key: Image Captioning by Skeleton-Attribute Decomposition", 
      "url": "https://www.semanticscholar.org/paper/0a904577358b9bae70d06c528adbcb6aa55d55bd"
    }, 
    {
      "isInfluential": false, 
      "paperId": "59927ded86ab4f7253fc32efb351e5a13e746ead", 
      "title": "TREETALK: Composition and Compression of Trees for Image Descriptions", 
      "url": "https://www.semanticscholar.org/paper/59927ded86ab4f7253fc32efb351e5a13e746ead"
    }, 
    {
      "isInfluential": false, 
      "paperId": "7710232a3d8bb1ef4ab0b5b6042bed19380bf0de", 
      "title": "Image description with a goal: Building efficient discriminating expressions for images", 
      "url": "https://www.semanticscholar.org/paper/7710232a3d8bb1ef4ab0b5b6042bed19380bf0de"
    }, 
    {
      "isInfluential": false, 
      "paperId": "204184e8a54c42bac589c19c3fa0c5d3d2c6009b", 
      "title": "Can Saliency Information Benefit Image Captioning Models?", 
      "url": "https://www.semanticscholar.org/paper/204184e8a54c42bac589c19c3fa0c5d3d2c6009b"
    }, 
    {
      "isInfluential": false, 
      "paperId": "79b566bd59a04d6ed8aa0bbffe1250cf955e841b", 
      "title": "A dataset for Movie Description", 
      "url": "https://www.semanticscholar.org/paper/79b566bd59a04d6ed8aa0bbffe1250cf955e841b"
    }
  ], 
  "doi": null, 
  "influentialCitationCount": 6, 
  "paperId": "b79f3d9f8de4d1cc6679676146a40d2a8596f32d", 
  "references": [
    {
      "isInfluential": false, 
      "paperId": "a25f7063e31d49aa96b6f9d6898ee2d4db016c6c", 
      "title": "DOGHED: A Template-Based Generator for Multimodal Dialog Systems Targeting Heterogeneous Devices", 
      "url": "https://www.semanticscholar.org/paper/a25f7063e31d49aa96b6f9d6898ee2d4db016c6c"
    }, 
    {
      "isInfluential": false, 
      "paperId": "2d6af4b5ef5eab25ddcc317c28be31ec9c2e3d7c", 
      "title": "Object Detection with Discriminatively Trained Part-Based Models", 
      "url": "https://www.semanticscholar.org/paper/2d6af4b5ef5eab25ddcc317c28be31ec9c2e3d7c"
    }, 
    {
      "isInfluential": false, 
      "paperId": "90d71f9d757ad5653e08cfa2106db9c16c4d6445", 
      "title": "Generating Image Descriptions Using Dependency Relational Patterns", 
      "url": "https://www.semanticscholar.org/paper/90d71f9d757ad5653e08cfa2106db9c16c4d6445"
    }, 
    {
      "isInfluential": true, 
      "paperId": "7fa51d9ebf688949571a86411c7baf13d30c74d0", 
      "title": "Bleu: a Method for Automatic Evaluation of Machine Translation", 
      "url": "https://www.semanticscholar.org/paper/7fa51d9ebf688949571a86411c7baf13d30c74d0"
    }, 
    {
      "isInfluential": false, 
      "paperId": "34bbda65483df5f3cae3c75e6b92545d7d03f24d", 
      "title": "Text Mining for Automatic Image Tagging", 
      "url": "https://www.semanticscholar.org/paper/34bbda65483df5f3cae3c75e6b92545d7d03f24d"
    }, 
    {
      "isInfluential": false, 
      "paperId": "1a81c722727299e45af289d905d7dcf157174248", 
      "title": "BabyTalk: Understanding and Generating Simple Image Descriptions", 
      "url": "https://www.semanticscholar.org/paper/1a81c722727299e45af289d905d7dcf157174248"
    }, 
    {
      "isInfluential": false, 
      "paperId": "a65a9b1ab2b1e617207be59d1724169d2ded88d0", 
      "title": "How Many Words Is a Picture Worth? Automatic Caption Generation for News Images", 
      "url": "https://www.semanticscholar.org/paper/a65a9b1ab2b1e617207be59d1724169d2ded88d0"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0e07c9a8b85893755ef9693b39cc0ecb09d96a49", 
      "title": "NLP for Indexing and Retrieval of Captioned Photographs", 
      "url": "https://www.semanticscholar.org/paper/0e07c9a8b85893755ef9693b39cc0ecb09d96a49"
    }, 
    {
      "isInfluential": false, 
      "paperId": "73209d66b1894ab5ce25ba70e1e39ed47dbbc11e", 
      "title": "Topic Models for Image Annotation and Text Illustration", 
      "url": "https://www.semanticscholar.org/paper/73209d66b1894ab5ce25ba70e1e39ed47dbbc11e"
    }, 
    {
      "isInfluential": false, 
      "paperId": "b4f4b0d39fd10baec34d3412d53515f1a4605222", 
      "title": "Every Picture Tells a Story: Generating Sentences from Images", 
      "url": "https://www.semanticscholar.org/paper/b4f4b0d39fd10baec34d3412d53515f1a4605222"
    }, 
    {
      "isInfluential": false, 
      "paperId": "2340ff1620b00f8cae0c66ea7504201895dde1ff", 
      "title": "Matching Words and Pictures", 
      "url": "https://www.semanticscholar.org/paper/2340ff1620b00f8cae0c66ea7504201895dde1ff"
    }, 
    {
      "isInfluential": false, 
      "paperId": "0de151d3e2a66aa0af70d1d45ad5e86024eac676", 
      "title": "I2T: Image Parsing to Text Description", 
      "url": "https://www.semanticscholar.org/paper/0de151d3e2a66aa0af70d1d45ad5e86024eac676"
    }, 
    {
      "isInfluential": false, 
      "paperId": "38211dc39e41273c0007889202c69f841e02248a", 
      "title": "ImageNet: A large-scale hierarchical image database", 
      "url": "https://www.semanticscholar.org/paper/38211dc39e41273c0007889202c69f841e02248a"
    }, 
    {
      "isInfluential": false, 
      "paperId": "18b534c7207a1376fa92e87fe0d2cfb358d98c51", 
      "title": "Accurate Unlexicalized Parsing", 
      "url": "https://www.semanticscholar.org/paper/18b534c7207a1376fa92e87fe0d2cfb358d98c51"
    }, 
    {
      "isInfluential": false, 
      "paperId": "d6a690bfd6c6e6d06a9f342b60e1a9c0505a4a49", 
      "title": "Template-Filtered Headline Summarization", 
      "url": "https://www.semanticscholar.org/paper/d6a690bfd6c6e6d06a9f342b60e1a9c0505a4a49"
    }, 
    {
      "isInfluential": false, 
      "paperId": "84af628278ca824a70678e930437742d3fa6b881", 
      "title": "Selecting Sentences For Multidocument Summaries Using Randomized Local Search", 
      "url": "https://www.semanticscholar.org/paper/84af628278ca824a70678e930437742d3fa6b881"
    }, 
    {
      "isInfluential": false, 
      "paperId": "7acdc25c34b81d6afdd5bca5f1d6029e6070b5c1", 
      "title": "Learning Decision Rules by Randomized Iterative Local Search", 
      "url": "https://www.semanticscholar.org/paper/7acdc25c34b81d6afdd5bca5f1d6029e6070b5c1"
    }, 
    {
      "isInfluential": false, 
      "paperId": "2e384f057211426ac5922f1b33d2aa8df5d51f57", 
      "title": "Describing objects by their attributes", 
      "url": "https://www.semanticscholar.org/paper/2e384f057211426ac5922f1b33d2aa8df5d51f57"
    }
  ], 
  "title": "Composing Simple Image Descriptions using Web-scale N-grams", 
  "url": "https://www.semanticscholar.org/paper/b79f3d9f8de4d1cc6679676146a40d2a8596f32d", 
  "venue": "CoNLL"
}
